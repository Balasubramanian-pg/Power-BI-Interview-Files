## 15. What are the trade-offs between using **calculated columns** in DAX vs. in Power Query M?

This is a fundamental data modeling choice with significant implications for performance, refresh time, and flexibility.

#### Calculated Columns in Power Query (M)
*   **When it's Calculated:** During data refresh.
*   **Pros:**
    *   **Pre-computed and Stored:** The values are calculated once during refresh and materialized in the table. This means they do not consume CPU resources at query time.
    *   **Better Compression:** Because the column is materialized before compression, the VertiPaq engine can apply standard compression techniques (like dictionary encoding) to it. If the resulting column has low cardinality, this is very efficient.
    *   **Can be Query-Folded:** If the transformation is supported, the calculation can be pushed back to the data source, which is highly efficient.
*   **Cons:**
    *   **Static:** The values are only updated when the dataset is refreshed. They cannot react to user selections (slicers) on the report.
    *   **No Access to Model Relationships:** M calculations are row-by-row and can only see data within the current table (or data explicitly merged from other queries). They cannot use DAX functions like `RELATED()` to look up values across model relationships.

#### Calculated Columns in DAX
*   **When it's Calculated:** During data refresh (or `Process Recalc`), after the tables are loaded into the model.
*   **Pros:**
    *   **Access to the Full Model:** DAX calculations have full awareness of the data model, including all tables, relationships, and measures. This allows for powerful logic using functions like `RELATED`, `CALCULATE`, etc.
    *   **Complex Row-Context Logic:** It can perform sophisticated calculations for each row based on values from related tables.
*   **Cons:**
    *   **Worse Compression:** DAX calculated columns are computed *after* the initial data load and compression. This often leads to less optimal compression compared to a column imported directly or created in Power Query.
    *   **Increased Model Size and Refresh Time:** Each DAX calculated column is stored in memory just like any other column, consuming RAM. Complex DAX columns can also add significant time to the data refresh process.
    *   **Static (like M columns):** Despite being written in DAX, calculated columns are still evaluated at refresh and are not dynamic. This is a common point of confusion; they do not respond to slicers.

> **Guideline:**
> * **Use Power Query M when:** The calculation is based only on other columns in the same row, is static, and doesn't require model relationships. This is the preferred method for data preparation.
> * **Use DAX Calculated Columns when:** The calculation for each row absolutely requires looking up values from other tables across model relationships (e.g., fetching a product category for each sales line).
> * **Use Measures when:** The calculation needs to be dynamic and respond to user filters and slicers.

---

### 16. How can **composite models** break query folding, and how do you troubleshoot that?

#### How Composite Models Break Query Folding
*   **The "Folding Wall":** Query folding works by translating M steps into a single query for a *single source*. A composite model, by definition, involves data from at least two different sources or storage modes (e.g., DirectQuery and Import).
*   **The Breaking Point:** The moment a Power Query transformation needs to combine data from a foldable source (like a SQL Server) with data from another source, folding stops cold.
    *   **Example 1: Merging DQ and Import:** You have a `Sales` table in DirectQuery mode from SQL Server and an `Sales Targets` table imported from an Excel file. When you perform a `Table.NestedJoin` (Merge Queries) step to combine them, Power BI cannot send a single query to SQL Server that includes data from a local Excel file.
    *   **Consequence:** To perform the merge, Power BI's mashup engine must first execute the folded query against the SQL server to retrieve *all the data up to that point*. It then pulls that data into its own memory and performs the merge locally with the Excel data. This negates the primary benefit of DirectQuery/folding, which is to keep data at the source.

#### Troubleshooting Steps
*   **Use the Query Diagnostics Tools:**
    *   In Power Query, go to the `Tools` tab and click `Start Diagnostics`. Perform the steps (like merging tables), then click `Stop Diagnostics`.
    *   This will generate detailed diagnostic tables that show you the queries being sent to the data source. You can see the native queries and identify which parts are being folded.
*   **Check "View Native Query" Step-by-Step:**
    *   This is the simplest method. Start from the first step in your query and right-click on each subsequent step.
    *   Observe at which step the `View Native Query` option becomes greyed out. This is your "folding breaker". The step immediately preceding it was the last successful folded operation.
*   **Reorder Steps Strategically:**
    *   Try to perform as many foldable transformations as possible *before* the step that breaks folding.
    *   For example, filter your SQL table and remove unnecessary columns first. Only then, as the last step, merge it with the data from the non-foldable source. This ensures the query sent to the SQL server is as efficient as possible.
*   **Consider Dataflows:**
    *   In some scenarios, you can use Power BI Dataflows to pre-combine and clean data. You can merge the SQL and Excel data in a dataflow. Then, in your Power BI Desktop file, you can connect to this single, pre-processed dataflow entity, which can simplify the model and query logic.

---

### 17. Why might you use **Calculation Items with TIME INTELLIGENCE** instead of writing multiple measures?

#### The Problem: "Measure Explosion"
*   **Traditional Approach:** For every base measure (like `[Total Sales]`, `[Total Quantity]`, `[Profit]`), you need to create a separate DAX measure for each time intelligence calculation.
    *   `Sales YTD = TOTALYTD([Total Sales], 'Date'[Date])`
    *   `Sales MTD = TOTALMTD([Total Sales], 'Date'[Date])`
    *   `Sales PY = CALCULATE([Total Sales], SAMEPERIODLASTYEAR('Date'[Date]))`
    *   `...`
    *   `Profit YTD = TOTALYTD([Profit], 'Date'[Date])`
    *   `Profit MTD = TOTALMTD([Profit], 'Date'[Date])`
    *   ...and so on.
*   **Result:** With 5 base measures and 5 time calculations, you end up with 25 time intelligence measures. This clutters the model, is difficult to maintain, and is prone to error.

#### The Solution: Calculation Items
*   **Centralized Logic:** Calculation groups allow you to define the time intelligence logic *once*.
*   **How it Works:**
    1.  You create a single Calculation Group, for example, named `Time Intelligence`.
    2.  Inside this group, you create Calculation Items for each desired calculation: "Current", "MTD", "YTD", "PY", etc.
    3.  The DAX for each item uses the `SELECTEDMEASURE()` function as a placeholder.
        *   **YTD Item DAX:** `CALCULATE(SELECTEDMEASURE(), DATESYTD('Date'[Date]))`
        *   **PY Item DAX:** `CALCULATE(SELECTEDMEASURE(), SAMEPERIODLASTYEAR('Date'[Date]))`
        *   **Current Item DAX:** `SELECTEDMEASURE()` (this shows the original, unmodified measure).

#### The Benefits
*   **Drastic Reduction in Measures:** Instead of 25 measures, you have your 5 base measures and one calculation group with 5 items. The model is dramatically simpler.
*   **Scalability and Maintenance:** If you need to add a new base measure (`[COGS]`), you don't need to create 5 new DAX measures for it. It will automatically work with the existing calculation group. If you need to fix the logic for PY, you only fix it in one place.
*   **Enhanced User Experience:** You can add the `Time Intelligence` calculation group to a slicer or as columns in a matrix. This allows users to dynamically switch a whole report or matrix between showing MTD, YTD, or PY values without needing to change pages or use bookmarks.
